from datetime import datetime
from app import db

class ActivityLog(db.Model):
    """Model for tracking activity in the application."""
    id = db.Column(db.Integer, primary_key=True)
    action = db.Column(db.String(100), nullable=False)
    details = db.Column(db.Text)
    created_at = db.Column(db.DateTime, default=datetime.now)
    
    def __repr__(self):
        return f"<ActivityLog {self.action}>"

class JobRun(db.Model):
    """Model for tracking scraper job runs."""
    id = db.Column(db.Integer, primary_key=True)
    start_time = db.Column(db.DateTime, default=datetime.now)
    end_time = db.Column(db.DateTime)
    status = db.Column(db.String(20))  # 'running', 'completed', 'failed'
    error = db.Column(db.Text)
    items_processed = db.Column(db.Integer, default=0)
    created_at = db.Column(db.DateTime, default=datetime.now)
    
    def __repr__(self):
        return f"<JobRun {self.id} - {self.status}>"

class NarrprCredential(db.Model):
    """Model for storing NARRPR credentials."""
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(255), nullable=False)
    password = db.Column(db.String(255), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.now)
    updated_at = db.Column(db.DateTime, default=datetime.now, onupdate=datetime.now)
    
    def __repr__(self):
        return f"<NarrprCredential {self.username}>"

class AIFeedback(db.Model):
    """Model for storing feedback on AI agent responses."""
    id = db.Column(db.Integer, primary_key=True)
    agent_type = db.Column(db.String(50), nullable=False)  # summarizer, market_analyzer, recommender, nl_search
    query_data = db.Column(db.Text, nullable=False)  # The input provided to the agent
    response_data = db.Column(db.Text, nullable=False)  # The response generated by the agent
    rating = db.Column(db.Integer, nullable=False)  # 1-5 star rating
    comments = db.Column(db.Text, nullable=True)  # Optional user comments
    session_id = db.Column(db.String(64), nullable=True)  # To group multiple interactions from same session
    prompt_version_id = db.Column(db.Integer, db.ForeignKey('prompt_version.id'), nullable=True)  # The prompt version used
    extra_data = db.Column(db.Text, nullable=True)  # JSON blob with additional metadata (e.g., A/B test data)
    created_at = db.Column(db.DateTime, default=datetime.now)
    updated_at = db.Column(db.DateTime, default=datetime.now, onupdate=datetime.now)
    
    # Relationship with prompt version
    prompt_version = db.relationship('PromptVersion', backref=db.backref('feedback', lazy=True))
    
    def __repr__(self):
        return f"<AIFeedback {self.agent_type} - {self.rating} stars>"
        
class AIFeedbackReportSettings(db.Model):
    """Model for storing AI feedback report settings."""
    id = db.Column(db.Integer, primary_key=True)
    
    # Recipients
    admin_email = db.Column(db.String(255), nullable=True)  # Primary admin email for reports
    additional_recipients = db.Column(db.Text, nullable=True)  # JSON array of additional email addresses
    
    # Schedule settings
    send_daily_reports = db.Column(db.Boolean, default=False)
    send_weekly_reports = db.Column(db.Boolean, default=True)
    send_monthly_reports = db.Column(db.Boolean, default=True)
    
    # Weekly report day (0-6, Monday to Sunday)
    weekly_report_day = db.Column(db.Integer, default=0)
    
    # Monthly report day (1-31)
    monthly_report_day = db.Column(db.Integer, default=1)
    
    # Report content settings
    include_detailed_feedback = db.Column(db.Boolean, default=True)
    include_csv_attachment = db.Column(db.Boolean, default=True)
    include_excel_attachment = db.Column(db.Boolean, default=True)
    
    # Updated timestamp
    updated_at = db.Column(db.DateTime, default=datetime.now, onupdate=datetime.now)
    
    def __repr__(self):
        return f"<AIFeedbackReportSettings id={self.id}>"
    
    @staticmethod
    def get_settings():
        """Get the current settings, creating default settings if none exist."""
        from app import db
        
        settings = AIFeedbackReportSettings.query.first()
        if not settings:
            settings = AIFeedbackReportSettings()
            db.session.add(settings)
            db.session.commit()
        
        return settings
        
class PromptABTest(db.Model):
    """Model for storing A/B test data for prompt optimization."""
    id = db.Column(db.Integer, primary_key=True)
    agent_type = db.Column(db.String(50), nullable=False)  # Type of agent being tested
    original_prompt = db.Column(db.Text, nullable=False)  # Version A (original)
    improved_prompt = db.Column(db.Text, nullable=False)  # Version B (improved)
    start_date = db.Column(db.DateTime, nullable=False, default=datetime.now)
    end_date = db.Column(db.DateTime, nullable=False)
    status = db.Column(db.String(20), nullable=False)  # 'active', 'completed', 'cancelled'
    results = db.Column(db.Text, nullable=True)  # JSON blob with test results
    created_at = db.Column(db.DateTime, default=datetime.now)
    updated_at = db.Column(db.DateTime, default=datetime.now, onupdate=datetime.now)
    
    def __repr__(self):
        return f"<PromptABTest id={self.id} agent={self.agent_type} status={self.status}>"
        
class PromptVersion(db.Model):
    """Model for storing prompt versions for different agents."""
    id = db.Column(db.Integer, primary_key=True)
    agent_type = db.Column(db.String(50), nullable=False)  # Type of agent
    version = db.Column(db.Integer, nullable=False)  # Version number
    prompt_text = db.Column(db.Text, nullable=False)  # The prompt text
    is_active = db.Column(db.Boolean, default=False)  # Whether this is the currently active version
    notes = db.Column(db.Text, nullable=True)  # Notes about this version
    created_at = db.Column(db.DateTime, default=datetime.now)
    updated_at = db.Column(db.DateTime, default=datetime.now, onupdate=datetime.now)
    
    def __repr__(self):
        return f"<PromptVersion id={self.id} agent={self.agent_type} v{self.version} active={self.is_active}>"
    
    @staticmethod
    def get_active_prompt(agent_type):
        """Get the active prompt for a specific agent type."""
        from app import db
        
        prompt = PromptVersion.query.filter_by(
            agent_type=agent_type,
            is_active=True
        ).order_by(PromptVersion.version.desc()).first()
        
        if not prompt:
            # If no active prompt exists, get the latest version
            prompt = PromptVersion.query.filter_by(
                agent_type=agent_type
            ).order_by(PromptVersion.version.desc()).first()
            
            if prompt:
                # Make it active
                prompt.is_active = True
                db.session.commit()
        
        return prompt
        
class LearningCycle(db.Model):
    """Model for tracking AI continuous learning cycles."""
    id = db.Column(db.Integer, primary_key=True)
    start_date = db.Column(db.DateTime, nullable=False, default=datetime.now)
    end_date = db.Column(db.DateTime, nullable=True)
    status = db.Column(db.String(20), nullable=False, default='in_progress')  # 'in_progress', 'completed', 'failed', 'cancelled'
    agents_processed = db.Column(db.Integer, default=0)  # Number of agents processed
    agents_optimized = db.Column(db.Integer, default=0)  # Number of agents that were successfully optimized
    average_improvement = db.Column(db.Float, default=0.0)  # Average percentage improvement across all agents
    error_message = db.Column(db.Text, nullable=True)  # Error message if failed
    results = db.Column(db.Text, nullable=True)  # JSON blob with detailed results
    created_at = db.Column(db.DateTime, default=datetime.now)
    updated_at = db.Column(db.DateTime, default=datetime.now, onupdate=datetime.now)
    
    def __repr__(self):
        return f"<LearningCycle id={self.id} status={self.status} agents_optimized={self.agents_optimized}>"
        
class AgentOptimizationResult(db.Model):
    """Model for storing results of agent optimizations in learning cycles."""
    id = db.Column(db.Integer, primary_key=True)
    learning_cycle_id = db.Column(db.Integer, db.ForeignKey('learning_cycle.id'), nullable=False)
    agent_type = db.Column(db.String(50), nullable=False)  # Type of agent
    original_prompt_id = db.Column(db.Integer, db.ForeignKey('prompt_version.id'), nullable=True)
    new_prompt_id = db.Column(db.Integer, db.ForeignKey('prompt_version.id'), nullable=True)
    original_rating = db.Column(db.Float, nullable=True)  # Average rating before optimization
    new_rating = db.Column(db.Float, nullable=True)  # Average rating after optimization
    improvement_percentage = db.Column(db.Float, nullable=True)  # Percentage improvement
    tests_run = db.Column(db.Integer, default=0)  # Number of A/B tests run
    successful = db.Column(db.Boolean, default=False)  # Whether optimization was successful
    applied = db.Column(db.Boolean, default=False)  # Whether the optimization was applied
    notes = db.Column(db.Text, nullable=True)  # Notes about the optimization
    created_at = db.Column(db.DateTime, default=datetime.now)
    
    # Relationships
    learning_cycle = db.relationship('LearningCycle', backref=db.backref('agent_results', lazy=True))
    original_prompt = db.relationship('PromptVersion', foreign_keys=[original_prompt_id])
    new_prompt = db.relationship('PromptVersion', foreign_keys=[new_prompt_id])
    
    def __repr__(self):
        return f"<AgentOptimizationResult id={self.id} agent={self.agent_type} improvement={self.improvement_percentage}%>"